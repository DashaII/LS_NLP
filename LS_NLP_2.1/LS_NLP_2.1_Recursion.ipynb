{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для чтения файла. Принимает путь к файлу, возвращает содержимое файла как строку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path, encoding = 'utf-8'):\n",
    "    with open(file_path) as input_file:\n",
    "        return input_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для определения бинарности файла. Принимает путь к файлу, возвращает true, если файл бинарный, false, если нет.\n",
    "(Воспользовалась гуглом, как и предлагалось. Работает только для UTF-8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_file_binary(file_path): \n",
    "    read_bytes = 3000 # будем читать столько байтов файла, чтобы протестировать его на бинарность\n",
    "    threshold = 0.15  # пороговое значение количества \"бинарных\" символов в файле, чтобы определить его бинарным\n",
    "    # набор \"текстовых\" символов, работает только для русского и английского алфавитов (все, что не текстовое, то бинарное)\n",
    "    text_characters = ''.join([chr(code) for code in range(32,127)] + \n",
    "                              [chr(code) for code in range(1040,1104)] + \n",
    "                              list('\\b\\f\\n\\r\\t'))\n",
    "\n",
    "    file = open(file_path, encoding = 'utf-8')\n",
    "    file_data = file.read(read_bytes)\n",
    "    file.close()\n",
    "\n",
    "    data_length = len(file_data)\n",
    "    if (not data_length):\n",
    "        return False # пустой файл считаем текстовым\n",
    "    if (chr(0) in file_data):                \n",
    "        return True # если находим null байт, то файл бинарный\n",
    "\n",
    "    mapping_table = file_data.maketrans('', '', text_characters)\n",
    "    binary_length = len(file_data.translate(mapping_table)) # удаляем все текстовые символы\n",
    "        \n",
    "    # если бинарных символов больше порогового значения, то считаем файл бинарным\n",
    "    return ((float(binary_length) / data_length) >= threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для формирования частотного словаря. Принимает текст и словарь, который будет дополнять. Возвращает дополненный словарь, отсортированный по убыванию значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_common_words(text, frequency_dict = {}):\n",
    "    \n",
    "    punctuations = '''-[]{};:'\"/\\\\/<>@#$%^&*_|—«»~=!().?,”'''\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    for sybmol in text: \n",
    "        if sybmol in punctuations: \n",
    "            text = text.replace(sybmol, ' ')\n",
    "\n",
    "    text_list = text.split()\n",
    "\n",
    "    for word in text_list:\n",
    "        count = frequency_dict.get(word, 0)\n",
    "        frequency_dict[word] = count + 1\n",
    "        \n",
    "    # сортируем частотный словарь\n",
    "    sorted_tuples = sorted(frequency_dict.items(), key = lambda item: item[1], reverse = True)\n",
    "    sorted_dict = {k: v for k, v in sorted_tuples}\n",
    "    \n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основая часть - изменить путь к папке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of .txt files in folder LS_Py_Tasks/recursion : \n",
      "\n",
      "Type : text    LS_Py_Tasks/recursion\\0_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\0_2.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\0_3.txt\n",
      "Type : binary  LS_Py_Tasks/recursion\\binary.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\1_folder\\1_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\1_folder\\1_1_folder\\1_1_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\1_folder\\1_1_folder\\1_1_1_folder\\1_1_1_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\1_folder\\1_2_folder\\1_2_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\1_folder\\1_2_folder\\1_2_1_folder\\1_2_1_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\1_folder\\1_2_folder\\1_2_2_folder\\1_2_2_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\1_folder\\1_2_folder\\1_2_2_folder\\1_2_2_2.txt\n",
      "Type : binary  LS_Py_Tasks/recursion\\1_folder\\1_2_folder\\1_2_2_folder\\binary_3.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\1_folder\\1_2_folder\\1_2_2_folder\\binary_4.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\1_folder\\1_2_folder\\1_2_2_folder\\1_2_2_1_folder\\1_2_2_1_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\2_folder\\2_1.txt\n",
      "Type : binary  LS_Py_Tasks/recursion\\2_folder\\binary_2.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\2_folder\\2_1_folder\\2_1_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\2_folder\\2_1_folder\\2_1_2.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\2_folder\\2_1_folder\\2_1_1_folder\\2_1_1_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\2_folder\\2_1_folder\\2_1_2_folder\\2_1_2_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\2_folder\\2_1_folder\\2_1_2_folder\\2_1_2_2.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\2_folder\\2_1_folder\\2_1_2_folder\\2_1_2_1_folder\\2_1_2_1_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\2_folder\\2_1_folder\\2_1_2_folder\\2_1_2_1_folder\\2_1_2_1_1_folder\\2_1_2_1_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\2_folder\\2_1_folder\\2_1_3_folder\\2_1_3_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\3_folder\\3_1.txt\n",
      "Type : text    LS_Py_Tasks/recursion\\3_folder\\3_1_folder\\3_1_1.txt\n",
      "\n",
      "Common words in folder LS_Py_Tasks/recursion : \n",
      "\n",
      "the: 229\n",
      "of: 214\n",
      "a: 126\n",
      "and: 101\n",
      "to: 91\n",
      "in: 87\n",
      "is: 68\n",
      "language: 55\n",
      "as: 45\n",
      "e: 41\n",
      "for: 39\n",
      "natural: 35\n",
      "g: 35\n",
      "nlp: 34\n",
      "or: 34\n",
      "that: 33\n",
      "text: 31\n",
      "such: 29\n",
      "on: 29\n",
      "with: 28\n",
      "are: 27\n",
      "machine: 26\n",
      "words: 26\n",
      "be: 25\n",
      "learning: 24\n",
      "given: 24\n",
      "more: 24\n",
      "can: 22\n",
      "systems: 22\n",
      "which: 22\n",
      "speech: 21\n",
      "by: 20\n",
      "this: 20\n",
      "processing: 18\n",
      "data: 18\n",
      "from: 18\n",
      "rules: 18\n",
      "statistical: 18\n",
      "other: 17\n",
      "semantic: 17\n",
      "sentence: 17\n",
      "tasks: 16\n",
      "semantics: 16\n",
      "parsing: 16\n",
      "task: 15\n",
      "based: 15\n",
      "since: 15\n",
      "have: 15\n",
      "cognitive: 15\n",
      "research: 14\n",
      "an: 14\n",
      "neural: 14\n",
      "has: 14\n",
      "into: 14\n",
      "not: 13\n",
      "however: 13\n",
      "many: 13\n",
      "methods: 13\n",
      "languages: 13\n",
      "input: 13\n",
      "word: 13\n",
      "used: 12\n",
      "models: 12\n",
      "translation: 12\n",
      "grammar: 12\n",
      "was: 11\n",
      "it: 11\n",
      "also: 11\n",
      "computer: 10\n",
      "information: 10\n",
      "recognition: 10\n",
      "example: 10\n",
      "analysis: 10\n",
      "when: 10\n",
      "algorithms: 10\n",
      "possible: 10\n",
      "linguistics: 9\n",
      "human: 9\n",
      "understanding: 9\n",
      "often: 9\n",
      "s: 9\n",
      "been: 9\n",
      "most: 9\n",
      "see: 9\n",
      "one: 9\n",
      "determine: 9\n",
      "discourse: 9\n",
      "but: 8\n",
      "they: 8\n",
      "all: 8\n",
      "morphology: 8\n",
      "separate: 8\n",
      "1990s: 8\n",
      "real: 8\n",
      "some: 8\n",
      "world: 8\n",
      "process: 7\n",
      "chunk: 7\n",
      "first: 7\n",
      "these: 7\n",
      "knowledge: 7\n",
      "english: 7\n",
      "being: 7\n",
      "symbolic: 7\n",
      "were: 7\n",
      "results: 7\n",
      "each: 7\n",
      "identify: 7\n",
      "between: 6\n",
      "documents: 6\n",
      "book: 6\n",
      "non: 6\n",
      "ai: 6\n",
      "different: 6\n",
      "use: 6\n",
      "aspects: 6\n",
      "at: 6\n",
      "1980s: 6\n",
      "like: 6\n",
      "hand: 6\n",
      "there: 6\n",
      "especially: 6\n",
      "increasingly: 6\n",
      "difficult: 6\n",
      "part: 6\n",
      "i: 6\n",
      "dictionary: 6\n",
      "context: 6\n",
      "form: 6\n",
      "segmentation: 6\n",
      "named: 6\n",
      "role: 6\n",
      "labelling: 6\n",
      "intelligence: 5\n",
      "generation: 5\n",
      "produce: 5\n",
      "system: 5\n",
      "network: 5\n",
      "people: 5\n",
      "thus: 5\n",
      "its: 5\n",
      "what: 5\n",
      "time: 5\n",
      "chinese: 5\n",
      "than: 5\n",
      "sentences: 5\n",
      "written: 5\n",
      "using: 5\n",
      "during: 5\n",
      "computational: 5\n",
      "structure: 5\n",
      "generally: 5\n",
      "typically: 5\n",
      "make: 5\n",
      "complexity: 5\n",
      "representation: 5\n",
      "set: 5\n",
      "automatically: 5\n",
      "extraction: 5\n",
      "question: 5\n",
      "aid: 5\n",
      "meaning: 5\n",
      "individual: 5\n",
      "coreference: 5\n",
      "names: 5\n",
      "resolution: 5\n",
      "argument: 5\n",
      "science: 4\n",
      "artificial: 4\n",
      "within: 4\n",
      "then: 4\n",
      "extract: 4\n",
      "level: 4\n",
      "applications: 4\n",
      "automatic: 4\n",
      "published: 4\n",
      "document: 4\n",
      "no: 4\n",
      "specific: 4\n",
      "grammatical: 4\n",
      "error: 4\n",
      "problems: 4\n",
      "syntax: 4\n",
      "due: 4\n",
      "development: 4\n",
      "problem: 4\n",
      "early: 4\n",
      "questions: 4\n",
      "those: 4\n",
      "much: 4\n",
      "sometimes: 4\n",
      "do: 4\n",
      "two: 4\n",
      "up: 4\n",
      "textual: 4\n",
      "supervised: 4\n",
      "learn: 4\n",
      "annotated: 4\n",
      "among: 4\n",
      "networks: 4\n",
      "common: 4\n",
      "structures: 4\n",
      "handwritten: 4\n",
      "only: 4\n",
      "so: 4\n",
      "through: 4\n",
      "typical: 4\n",
      "probabilistic: 4\n",
      "larger: 4\n",
      "multiple: 4\n",
      "end: 4\n",
      "dependency: 4\n",
      "serve: 4\n",
      "below: 4\n",
      "person: 4\n",
      "any: 4\n",
      "trends: 4\n",
      "intent: 4\n",
      "relationships: 4\n",
      "entities: 4\n",
      "door: 4\n",
      "concerned: 3\n",
      "how: 3\n",
      "large: 3\n",
      "amounts: 3\n",
      "result: 3\n",
      "higher: 3\n",
      "summarization: 3\n",
      "known: 3\n",
      "type: 3\n",
      "proper: 3\n",
      "creation: 3\n",
      "generated: 3\n",
      "rule: 3\n",
      "racter: 3\n",
      "both: 3\n",
      "free: 3\n",
      "2019: 3\n",
      "experience: 3\n",
      "types: 3\n",
      "technical: 3\n",
      "correction: 3\n",
      "involves: 3\n",
      "shared: 3\n",
      "now: 3\n",
      "considered: 3\n",
      "largely: 3\n",
      "1950s: 3\n",
      "called: 3\n",
      "john: 3\n",
      "answers: 3\n",
      "long: 3\n",
      "late: 3\n",
      "developed: 3\n",
      "eliza: 3\n",
      "about: 3\n",
      "very: 3\n",
      "base: 3\n",
      "examples: 3\n",
      "areas: 3\n",
      "algorithm: 3\n",
      "theory: 3\n",
      "turn: 3\n",
      "increase: 3\n",
      "corpus: 3\n",
      "approach: 3\n",
      "field: 3\n",
      "corpora: 3\n",
      "produced: 3\n",
      "corresponding: 3\n",
      "major: 3\n",
      "increasing: 3\n",
      "focused: 3\n",
      "accurate: 3\n",
      "amount: 3\n",
      "if: 3\n",
      "deep: 3\n",
      "stemming: 3\n",
      "soft: 3\n",
      "decisions: 3\n",
      "made: 3\n",
      "simply: 3\n",
      "without: 3\n",
      "commonly: 3\n",
      "approaches: 3\n",
      "explicit: 3\n",
      "relative: 3\n",
      "tagging: 3\n",
      "include: 3\n",
      "may: 3\n",
      "another: 3\n",
      "termed: 3\n",
      "etc: 3\n",
      "formal: 3\n",
      "representations: 3\n",
      "usually: 3\n",
      "implicit: 3\n",
      "open: 3\n",
      "true: 3\n",
      "speaking: 3\n",
      "above: 3\n",
      "spoken: 3\n",
      "same: 3\n",
      "terms: 3\n",
      "boundaries: 3\n",
      "mining: 3\n",
      "lemmatization: 3\n",
      "their: 3\n",
      "turkish: 3\n",
      "will: 3\n",
      "entity: 3\n",
      "big: 3\n",
      "tree: 3\n",
      "piece: 3\n",
      "disambiguation: 3\n",
      "objects: 3\n",
      "predicates: 3\n",
      "we: 3\n",
      "capitalization: 3\n",
      "recognizing: 3\n",
      "several: 3\n",
      "identifying: 3\n",
      "sense: 3\n",
      "relationship: 3\n",
      "includes: 3\n",
      "roles: 3\n",
      "front: 3\n",
      "topic: 3\n",
      "computers: 2\n",
      "particular: 2\n",
      "analyze: 2\n",
      "including: 2\n",
      "them: 2\n",
      "technology: 2\n",
      "well: 2\n",
      "frequently: 2\n",
      "involve: 2\n",
      "readable: 2\n",
      "provide: 2\n",
      "extension: 2\n",
      "full: 2\n",
      "fledged: 2\n",
      "work: 2\n",
      "2018: 2\n",
      "1: 2\n",
      "road: 2\n",
      "marketed: 2\n",
      "contains: 2\n",
      "sixty: 2\n",
      "elaborate: 2\n",
      "intended: 2\n",
      "quickly: 2\n",
      "need: 2\n",
      "hidden: 2\n",
      "great: 2\n",
      "orthography: 2\n",
      "number: 2\n",
      "2011: 2\n",
      "2: 2\n",
      "solved: 2\n",
      "various: 2\n",
      "turing: 2\n",
      "premise: 2\n",
      "experiment: 2\n",
      "matching: 2\n",
      "authors: 2\n",
      "three: 2\n",
      "five: 2\n",
      "would: 2\n",
      "after: 2\n",
      "1966: 2\n",
      "had: 2\n",
      "further: 2\n",
      "1960s: 2\n",
      "restricted: 2\n",
      "thought: 2\n",
      "provided: 2\n",
      "might: 2\n",
      "head: 2\n",
      "hurts: 2\n",
      "1970s: 2\n",
      "conceptual: 2\n",
      "1978: 2\n",
      "lehnert: 2\n",
      "units: 2\n",
      "chatterbots: 2\n",
      "mark: 2\n",
      "focus: 2\n",
      "included: 2\n",
      "operationalization: 2\n",
      "important: 2\n",
      "2010s: 2\n",
      "complex: 2\n",
      "revolution: 2\n",
      "introduction: 2\n",
      "able: 2\n",
      "take: 2\n",
      "advantage: 2\n",
      "existing: 2\n",
      "canada: 2\n",
      "specifically: 2\n",
      "limited: 2\n",
      "web: 2\n",
      "become: 2\n",
      "available: 2\n",
      "mid: 2\n",
      "less: 2\n",
      "things: 2\n",
      "content: 2\n",
      "wide: 2\n",
      "low: 2\n",
      "techniques: 2\n",
      "achieve: 2\n",
      "modeling: 2\n",
      "others: 2\n",
      "where: 2\n",
      "study: 2\n",
      "12: 2\n",
      "designed: 2\n",
      "writing: 2\n",
      "recent: 2\n",
      "over: 2\n",
      "procedures: 2\n",
      "cases: 2\n",
      "whereas: 2\n",
      "inference: 2\n",
      "robust: 2\n",
      "unfamiliar: 2\n",
      "before: 2\n",
      "creating: 2\n",
      "extremely: 2\n",
      "beyond: 2\n",
      "significant: 2\n",
      "2020: 2\n",
      "insufficient: 2\n",
      "apply: 2\n",
      "resource: 2\n",
      "pipelines: 2\n",
      "tokenization: 2\n",
      "syntactic: 2\n",
      "parses: 2\n",
      "ties: 2\n",
      "towards: 2\n",
      "frameworks: 2\n",
      "construction: 2\n",
      "ideas: 2\n",
      "multimodal: 2\n",
      "although: 2\n",
      "16: 2\n",
      "paradigm: 2\n",
      "instead: 2\n",
      "features: 2\n",
      "attaching: 2\n",
      "valued: 2\n",
      "weights: 2\n",
      "feature: 2\n",
      "rather: 2\n",
      "reliable: 2\n",
      "model: 2\n",
      "trees: 2\n",
      "similar: 2\n",
      "subtasks: 2\n",
      "relevant: 2\n",
      "2015: 2\n",
      "answering: 2\n",
      "intermediate: 2\n",
      "fact: 2\n",
      "sequence: 2\n",
      "works: 2\n",
      "build: 2\n",
      "18: 2\n",
      "list: 2\n",
      "closely: 2\n",
      "class: 2\n",
      "colloquially: 2\n",
      "complete: 2\n",
      "requiring: 2\n",
      "convert: 2\n",
      "programs: 2\n",
      "identification: 2\n",
      "derived: 2\n",
      "expression: 2\n",
      "formalization: 2\n",
      "closed: 2\n",
      "assumption: 2\n",
      "vs: 2\n",
      "subjective: 2\n",
      "yes: 2\n",
      "false: 2\n",
      "answer: 2\n",
      "even: 2\n",
      "representing: 2\n",
      "sound: 2\n",
      "clip: 2\n",
      "successive: 2\n",
      "subtask: 2\n",
      "characters: 2\n",
      "fairly: 2\n",
      "japanese: 2\n",
      "morphological: 2\n",
      "inflectional: 2\n",
      "reducing: 2\n",
      "case: 2\n",
      "map: 2\n",
      "morphemes: 2\n",
      "forms: 2\n",
      "thousands: 2\n",
      "parts: 2\n",
      "noun: 2\n",
      "verb: 2\n",
      "out: 2\n",
      "close: 2\n",
      "general: 2\n",
      "future: 2\n",
      "directions: 2\n",
      "standing: 2\n",
      "conll: 2\n",
      "interest: 2\n",
      "1999: 2\n",
      "2002: 2\n",
      "2006: 2\n",
      "09: 2\n",
      "2017: 2\n",
      "spanish: 2\n",
      "german: 2\n",
      "arabic: 2\n",
      "cognition: 2\n",
      "behaviour: 2\n",
      "senses: 2\n",
      "interdisciplinary: 2\n",
      "lakoff: 2\n",
      "idea: 2\n",
      "author: 2\n",
      "imply: 2\n",
      "ambiguous: 2\n",
      "presented: 2\n",
      "pcfg: 2\n",
      "marking: 2\n",
      "parse: 2\n",
      "primary: 2\n",
      "constituency: 2\n",
      "focuses: 2\n",
      "lexical: 2\n",
      "capitalized: 2\n",
      "nouns: 2\n",
      "sentiment: 2\n",
      "online: 2\n",
      "terminology: 2\n",
      "goal: 2\n",
      "either: 2\n",
      "single: 2\n",
      "disambiguate: 2\n",
      "verbal: 2\n",
      "frames: 2\n",
      "classify: 2\n",
      "refer: 2\n",
      "anaphora: 2\n",
      "bridging: 2\n",
      "referring: 2\n",
      "house: 2\n",
      "referred: 2\n",
      "related: 2\n",
      "current: 2\n",
      "explicitly: 2\n",
      "realized: 2\n",
      "entails: 2\n",
      "argumentative: 2\n",
      "main: 2\n",
      "subfield: 1\n",
      "interactions: 1\n",
      "program: 1\n",
      "capable: 1\n",
      "contents: 1\n",
      "contextual: 1\n",
      "nuances: 1\n",
      "accurately: 1\n",
      "insights: 1\n",
      "contained: 1\n",
      "categorize: 1\n",
      "organize: 1\n",
      "themselves: 1\n",
      "challenges: 1\n",
      "summary: 1\n",
      "summaries: 1\n",
      "papers: 1\n",
      "articles: 1\n",
      "financial: 1\n",
      "section: 1\n",
      "newspaper: 1\n",
      "books: 1\n",
      "created: 1\n",
      "1984: 1\n",
      "policeman: 1\n",
      "beard: 1\n",
      "half: 1\n",
      "constructed: 1\n",
      "27: 1\n",
      "novel: 1\n",
      "million: 1\n",
      "basically: 1\n",
      "sensical: 1\n",
      "beta: 1\n",
      "writer: 1\n",
      "lithium: 1\n",
      "ion: 1\n",
      "batteries: 1\n",
      "springer: 1\n",
      "cham: 1\n",
      "28: 1\n",
      "unlike: 1\n",
      "grounded: 1\n",
      "factual: 1\n",
      "dialogue: 1\n",
      "management: 1\n",
      "converse: 1\n",
      "platform: 1\n",
      "sits: 1\n",
      "top: 1\n",
      "enabling: 1\n",
      "users: 1\n",
      "prior: 1\n",
      "train: 1\n",
      "powered: 1\n",
      "enables: 1\n",
      "teams: 1\n",
      "access: 1\n",
      "lawyers: 1\n",
      "business: 1\n",
      "analysts: 1\n",
      "accountants: 1\n",
      "29: 1\n",
      "detection: 1\n",
      "band: 1\n",
      "width: 1\n",
      "levels: 1\n",
      "linguistic: 1\n",
      "phonology: 1\n",
      "pragmatics: 1\n",
      "impactful: 1\n",
      "affects: 1\n",
      "hundreds: 1\n",
      "millions: 1\n",
      "acquire: 1\n",
      "second: 1\n",
      "subject: 1\n",
      "30: 1\n",
      "31: 1\n",
      "32: 1\n",
      "far: 1\n",
      "certain: 1\n",
      "powerful: 1\n",
      "gpt: 1\n",
      "commercial: 1\n",
      "33: 1\n",
      "roots: 1\n",
      "already: 1\n",
      "1950: 1\n",
      "alan: 1\n",
      "article: 1\n",
      "titled: 1\n",
      "computing: 1\n",
      "machinery: 1\n",
      "proposed: 1\n",
      "test: 1\n",
      "criterion: 1\n",
      "automated: 1\n",
      "interpretation: 1\n",
      "articulated: 1\n",
      "summarized: 1\n",
      "searle: 1\n",
      "room: 1\n",
      "collection: 1\n",
      "phrasebook: 1\n",
      "emulates: 1\n",
      "applying: 1\n",
      "confronted: 1\n",
      "georgetown: 1\n",
      "1954: 1\n",
      "involved: 1\n",
      "fully: 1\n",
      "russian: 1\n",
      "claimed: 1\n",
      "years: 1\n",
      "progress: 1\n",
      "slower: 1\n",
      "alpac: 1\n",
      "report: 1\n",
      "found: 1\n",
      "ten: 1\n",
      "year: 1\n",
      "failed: 1\n",
      "fulfill: 1\n",
      "expectations: 1\n",
      "funding: 1\n",
      "dramatically: 1\n",
      "reduced: 1\n",
      "little: 1\n",
      "conducted: 1\n",
      "until: 1\n",
      "notably: 1\n",
      "successful: 1\n",
      "shrdlu: 1\n",
      "working: 1\n",
      "blocks: 1\n",
      "worlds: 1\n",
      "vocabularies: 1\n",
      "simulation: 1\n",
      "rogerian: 1\n",
      "psychotherapist: 1\n",
      "joseph: 1\n",
      "weizenbaum: 1\n",
      "1964: 1\n",
      "almost: 1\n",
      "emotion: 1\n",
      "startlingly: 1\n",
      "interaction: 1\n",
      "patient: 1\n",
      "exceeded: 1\n",
      "small: 1\n",
      "generic: 1\n",
      "response: 1\n",
      "responding: 1\n",
      "my: 1\n",
      "why: 1\n",
      "you: 1\n",
      "say: 1\n",
      "your: 1\n",
      "programmers: 1\n",
      "began: 1\n",
      "write: 1\n",
      "ontologies: 1\n",
      "structured: 1\n",
      "understandable: 1\n",
      "margie: 1\n",
      "schank: 1\n",
      "1975: 1\n",
      "sam: 1\n",
      "cullingford: 1\n",
      "pam: 1\n",
      "wilensky: 1\n",
      "talespin: 1\n",
      "meehan: 1\n",
      "1976: 1\n",
      "qualm: 1\n",
      "1977: 1\n",
      "politics: 1\n",
      "carbonell: 1\n",
      "1979: 1\n",
      "plot: 1\n",
      "1981: 1\n",
      "parry: 1\n",
      "hey: 1\n",
      "day: 1\n",
      "hpsg: 1\n",
      "generative: 1\n",
      "3: 1\n",
      "lesk: 1\n",
      "reference: 1\n",
      "centering: 1\n",
      "4: 1\n",
      "rhetorical: 1\n",
      "lines: 1\n",
      "continued: 1\n",
      "jabberwacky: 1\n",
      "eventually: 1\n",
      "led: 1\n",
      "rising: 1\n",
      "importance: 1\n",
      "quantitative: 1\n",
      "evaluation: 1\n",
      "period: 1\n",
      "5: 1\n",
      "sets: 1\n",
      "starting: 1\n",
      "steady: 1\n",
      "power: 1\n",
      "moore: 1\n",
      "law: 1\n",
      "gradual: 1\n",
      "lessening: 1\n",
      "dominance: 1\n",
      "chomskyan: 1\n",
      "theories: 1\n",
      "transformational: 1\n",
      "whose: 1\n",
      "theoretical: 1\n",
      "underpinnings: 1\n",
      "discouraged: 1\n",
      "sort: 1\n",
      "underlies: 1\n",
      "6: 1\n",
      "notable: 1\n",
      "successes: 1\n",
      "occurred: 1\n",
      "ibm: 1\n",
      "multilingual: 1\n",
      "parliament: 1\n",
      "european: 1\n",
      "union: 1\n",
      "laws: 1\n",
      "calling: 1\n",
      "governmental: 1\n",
      "proceedings: 1\n",
      "official: 1\n",
      "government: 1\n",
      "depended: 1\n",
      "implemented: 1\n",
      "continues: 1\n",
      "limitation: 1\n",
      "success: 1\n",
      "deal: 1\n",
      "gone: 1\n",
      "effectively: 1\n",
      "2000s: 1\n",
      "growth: 1\n",
      "raw: 1\n",
      "unannotated: 1\n",
      "unsupervised: 1\n",
      "semi: 1\n",
      "desired: 1\n",
      "combination: 1\n",
      "produces: 1\n",
      "enormous: 1\n",
      "entire: 1\n",
      "inferior: 1\n",
      "enough: 1\n",
      "practical: 1\n",
      "present: 1\n",
      "style: 1\n",
      "became: 1\n",
      "widespread: 1\n",
      "flurry: 1\n",
      "showing: 1\n",
      "7: 1\n",
      "8: 1\n",
      "state: 1\n",
      "art: 1\n",
      "9: 1\n",
      "10: 1\n",
      "11: 1\n",
      "medicine: 1\n",
      "healthcare: 1\n",
      "notes: 1\n",
      "electronic: 1\n",
      "health: 1\n",
      "records: 1\n",
      "otherwise: 1\n",
      "inaccessible: 1\n",
      "seeking: 1\n",
      "improve: 1\n",
      "care: 1\n",
      "statistics: 1\n",
      "days: 1\n",
      "coding: 1\n",
      "coupled: 1\n",
      "lookup: 1\n",
      "13: 1\n",
      "14: 1\n",
      "grammars: 1\n",
      "devising: 1\n",
      "heuristic: 1\n",
      "advantages: 1\n",
      "obvious: 1\n",
      "effort: 1\n",
      "should: 1\n",
      "directed: 1\n",
      "containing: 1\n",
      "seen: 1\n",
      "erroneous: 1\n",
      "misspelled: 1\n",
      "accidentally: 1\n",
      "omitted: 1\n",
      "handling: 1\n",
      "gracefully: 1\n",
      "prone: 1\n",
      "consuming: 1\n",
      "supplying: 1\n",
      "limit: 1\n",
      "unmanageable: 1\n",
      "requires: 1\n",
      "man: 1\n",
      "hours: 1\n",
      "worked: 1\n",
      "increases: 1\n",
      "annotation: 1\n",
      "despite: 1\n",
      "popularity: 1\n",
      "still: 1\n",
      "training: 1\n",
      "successfully: 1\n",
      "apertium: 1\n",
      "preprocessing: 1\n",
      "postprocessing: 1\n",
      "transforming: 1\n",
      "output: 1\n",
      "historical: 1\n",
      "heritage: 1\n",
      "addressed: 1\n",
      "nevertheless: 1\n",
      "develop: 1\n",
      "technically: 1\n",
      "operationalizable: 1\n",
      "pursued: 1\n",
      "42: 1\n",
      "functional: 1\n",
      "43: 1\n",
      "44: 1\n",
      "psycholinguistics: 1\n",
      "neuroscience: 1\n",
      "act: 1\n",
      "r: 1\n",
      "uptake: 1\n",
      "mainstream: 1\n",
      "measured: 1\n",
      "presence: 1\n",
      "conferences: 1\n",
      "45: 1\n",
      "acl: 1\n",
      "recently: 1\n",
      "revived: 1\n",
      "explainability: 1\n",
      "under: 1\n",
      "notion: 1\n",
      "46: 1\n",
      "likewise: 1\n",
      "inherent: 1\n",
      "rarely: 1\n",
      "47: 1\n",
      "15: 1\n",
      "relied: 1\n",
      "heavily: 1\n",
      "calls: 1\n",
      "plural: 1\n",
      "possibly: 1\n",
      "annotations: 1\n",
      "classes: 1\n",
      "applied: 1\n",
      "express: 1\n",
      "certainty: 1\n",
      "producing: 1\n",
      "component: 1\n",
      "earliest: 1\n",
      "decision: 1\n",
      "hard: 1\n",
      "introduced: 1\n",
      "markov: 1\n",
      "making: 1\n",
      "cache: 1\n",
      "upon: 1\n",
      "rely: 1\n",
      "errors: 1\n",
      "integrated: 1\n",
      "comprising: 1\n",
      "replaced: 1\n",
      "continue: 1\n",
      "contexts: 1\n",
      "interpretability: 1\n",
      "transparency: 1\n",
      "required: 1\n",
      "drawback: 1\n",
      "require: 1\n",
      "engineering: 1\n",
      "17: 1\n",
      "abandoned: 1\n",
      "shifted: 1\n",
      "popular: 1\n",
      "embeddings: 1\n",
      "capture: 1\n",
      "properties: 1\n",
      "relying: 1\n",
      "pipeline: 1\n",
      "shift: 1\n",
      "entailed: 1\n",
      "substantial: 1\n",
      "changes: 1\n",
      "viewed: 1\n",
      "new: 1\n",
      "distinct: 1\n",
      "instance: 1\n",
      "term: 1\n",
      "nmt: 1\n",
      "emphasizes: 1\n",
      "directly: 1\n",
      "transformations: 1\n",
      "obviating: 1\n",
      "steps: 1\n",
      "alignment: 1\n",
      "smt: 1\n",
      "latest: 1\n",
      "tend: 1\n",
      "following: 1\n",
      "researched: 1\n",
      "direct: 1\n",
      "while: 1\n",
      "solving: 1\n",
      "though: 1\n",
      "intertwined: 1\n",
      "subdivided: 1\n",
      "categories: 1\n",
      "convenience: 1\n",
      "coarse: 1\n",
      "division: 1\n",
      "translate: 1\n",
      "member: 1\n",
      "humans: 1\n",
      "possess: 1\n",
      "facts: 1\n",
      "solve: 1\n",
      "properly: 1\n",
      "nlg: 1\n",
      "databases: 1\n",
      "intents: 1\n",
      "nlu: 1\n",
      "chunks: 1\n",
      "order: 1\n",
      "logic: 1\n",
      "easier: 1\n",
      "manipulate: 1\n",
      "takes: 1\n",
      "organized: 1\n",
      "notations: 1\n",
      "concepts: 1\n",
      "metamodel: 1\n",
      "ontology: 1\n",
      "efficient: 1\n",
      "empirical: 1\n",
      "solutions: 1\n",
      "confusions: 1\n",
      "assumptions: 1\n",
      "cwa: 1\n",
      "objective: 1\n",
      "expected: 1\n",
      "basis: 1\n",
      "34: 1\n",
      "right: 1\n",
      "capital: 1\n",
      "ended: 1\n",
      "life: 1\n",
      "looked: 1\n",
      "35: 1\n",
      "optical: 1\n",
      "character: 1\n",
      "ocr: 1\n",
      "image: 1\n",
      "printed: 1\n",
      "opposite: 1\n",
      "hardly: 1\n",
      "pauses: 1\n",
      "necessary: 1\n",
      "sounds: 1\n",
      "letters: 1\n",
      "blend: 1\n",
      "coarticulation: 1\n",
      "conversion: 1\n",
      "analog: 1\n",
      "signal: 1\n",
      "discrete: 1\n",
      "accents: 1\n",
      "software: 1\n",
      "must: 1\n",
      "recognize: 1\n",
      "variety: 1\n",
      "identical: 1\n",
      "equivalent: 1\n",
      "grouped: 1\n",
      "transform: 1\n",
      "visually: 1\n",
      "impaired: 1\n",
      "19: 1\n",
      "continuous: 1\n",
      "trivial: 1\n",
      "separated: 1\n",
      "spaces: 1\n",
      "thai: 1\n",
      "fashion: 1\n",
      "vocabulary: 1\n",
      "bag: 1\n",
      "bow: 1\n",
      "removing: 1\n",
      "endings: 1\n",
      "return: 1\n",
      "lemma: 1\n",
      "technique: 1\n",
      "normalized: 1\n",
      "transformation: 1\n",
      "actually: 1\n",
      "uses: 1\n",
      "actual: 1\n",
      "20: 1\n",
      "difficulty: 1\n",
      "depends: 1\n",
      "greatly: 1\n",
      "simple: 1\n",
      "ignore: 1\n",
      "entirely: 1\n",
      "opens: 1\n",
      "opened: 1\n",
      "opening: 1\n",
      "meitei: 1\n",
      "21: 1\n",
      "highly: 1\n",
      "agglutinated: 1\n",
      "indian: 1\n",
      "entry: 1\n",
      "pos: 1\n",
      "ones: 1\n",
      "table: 1\n",
      "flight: 1\n",
      "adjective: 1\n",
      "least: 1\n",
      "inflected: 1\n",
      "root: 1\n",
      "closing: 1\n",
      "closer: 1\n",
      "yields: 1\n",
      "does: 1\n",
      "grounds: 1\n",
      "tendencies: 1\n",
      "extrapolate: 1\n",
      "topics: 1\n",
      "series: 1\n",
      "observed: 1\n",
      "36: 1\n",
      "abstract: 1\n",
      "2001: 1\n",
      "shallow: 1\n",
      "03: 1\n",
      "2004: 1\n",
      "05: 1\n",
      "2008: 1\n",
      "multilinguality: 1\n",
      "potentially: 1\n",
      "multimodality: 1\n",
      "dutch: 1\n",
      "2003: 1\n",
      "bulgarian: 1\n",
      "danish: 1\n",
      "portuguese: 1\n",
      "slovenian: 1\n",
      "swedish: 1\n",
      "basque: 1\n",
      "catalan: 1\n",
      "greek: 1\n",
      "hungarian: 1\n",
      "italian: 1\n",
      "2007: 1\n",
      "czech: 1\n",
      "2009: 1\n",
      "2012: 1\n",
      "40+: 1\n",
      "60+: 1\n",
      "100+: 1\n",
      "elimination: 1\n",
      "weakly: 1\n",
      "emulate: 1\n",
      "intelligent: 1\n",
      "apparent: 1\n",
      "comprehension: 1\n",
      "broadly: 1\n",
      "advanced: 1\n",
      "represents: 1\n",
      "developmental: 1\n",
      "trajectories: 1\n",
      "refers: 1\n",
      "mental: 1\n",
      "action: 1\n",
      "acquiring: 1\n",
      "37: 1\n",
      "scientific: 1\n",
      "mind: 1\n",
      "processes: 1\n",
      "38: 1\n",
      "branch: 1\n",
      "combining: 1\n",
      "psychology: 1\n",
      "39: 1\n",
      "age: 1\n",
      "area: 1\n",
      "maintained: 1\n",
      "strong: 1\n",
      "studies: 1\n",
      "george: 1\n",
      "offers: 1\n",
      "methodology: 1\n",
      "perspective: 1\n",
      "along: 1\n",
      "findings: 1\n",
      "40: 1\n",
      "defining: 1\n",
      "metaphor: 1\n",
      "explained: 1\n",
      "вђњthe: 1\n",
      "anotherвђќ: 1\n",
      "provides: 1\n",
      "41: 1\n",
      "consider: 1\n",
      "вђњbigвђќ: 1\n",
      "comparison: 1\n",
      "вђњthat: 1\n",
      "treeвђќ: 1\n",
      "вђќphysically: 1\n",
      "largeвђќ: 1\n",
      "metaphorically: 1\n",
      "вђќtomorrow: 1\n",
      "dayвђќ: 1\n",
      "authorвђ™s: 1\n",
      "вђќimportanceвђќ: 1\n",
      "behind: 1\n",
      "usages: 1\n",
      "вђќshe: 1\n",
      "personвђќ: 1\n",
      "remain: 1\n",
      "somewhat: 1\n",
      "alike: 1\n",
      "additional: 1\n",
      "assign: 1\n",
      "measures: 1\n",
      "phrase: 1\n",
      "analyzed: 1\n",
      "means: 1\n",
      "mathematical: 1\n",
      "equation: 1\n",
      "us: 1\n",
      "patent: 1\n",
      "9269353: 1\n",
      "induction: 1\n",
      "22: 1\n",
      "generate: 1\n",
      "describes: 1\n",
      "breaking: 1\n",
      "boundary: 1\n",
      "find: 1\n",
      "marked: 1\n",
      "periods: 1\n",
      "punctuation: 1\n",
      "marks: 1\n",
      "purposes: 1\n",
      "abbreviations: 1\n",
      "analyses: 1\n",
      "perhaps: 1\n",
      "surprisingly: 1\n",
      "potential: 1\n",
      "seem: 1\n",
      "completely: 1\n",
      "nonsensical: 1\n",
      "building: 1\n",
      "stochastic: 1\n",
      "distributional: 1\n",
      "ner: 1\n",
      "stream: 1\n",
      "items: 1\n",
      "places: 1\n",
      "name: 1\n",
      "location: 1\n",
      "organization: 1\n",
      "cannot: 1\n",
      "determining: 1\n",
      "inaccurate: 1\n",
      "letter: 1\n",
      "span: 1\n",
      "furthermore: 1\n",
      "western: 1\n",
      "scripts: 1\n",
      "consistently: 1\n",
      "distinguish: 1\n",
      "capitalizes: 1\n",
      "regardless: 1\n",
      "whether: 1\n",
      "french: 1\n",
      "capitalize: 1\n",
      "adjectives: 1\n",
      "reviews: 1\n",
      "polarity: 1\n",
      "useful: 1\n",
      "public: 1\n",
      "opinion: 1\n",
      "social: 1\n",
      "media: 1\n",
      "marketing: 1\n",
      "select: 1\n",
      "makes: 1\n",
      "associated: 1\n",
      "wordnet: 1\n",
      "relational: 1\n",
      "who: 1\n",
      "married: 1\n",
      "whom: 1\n",
      "graph: 1\n",
      "amr: 1\n",
      "accordance: 1\n",
      "logical: 1\n",
      "formalism: 1\n",
      "drt: 1\n",
      "challenge: 1\n",
      "elementary: 1\n",
      "extended: 1\n",
      "frame: 1\n",
      "elements: 1\n",
      "mentions: 1\n",
      "pronouns: 1\n",
      "involving: 1\n",
      "expressions: 1\n",
      "he: 1\n",
      "entered: 1\n",
      "identified: 1\n",
      "rubric: 1\n",
      "connected: 1\n",
      "nature: 1\n",
      "elaboration: 1\n",
      "explanation: 1\n",
      "contrast: 1\n",
      "classifying: 1\n",
      "acts: 1\n",
      "statement: 1\n",
      "assertion: 1\n",
      "arguments: 1\n",
      "elsewhere: 1\n",
      "specified: 1\n",
      "resolve: 1\n",
      "former: 1\n",
      "against: 1\n",
      "local: 1\n",
      "zero: 1\n",
      "pro: 1\n",
      "drop: 1\n",
      "entailment: 1\n",
      "fragments: 1\n",
      "negation: 1\n",
      "allows: 1\n",
      "23: 1\n",
      "segments: 1\n",
      "devoted: 1\n",
      "segment: 1\n",
      "24: 1\n",
      "conclusions: 1\n",
      "scheme: 1\n",
      "subsidiary: 1\n",
      "counter: 1\n",
      "25: 1\n",
      "26: 1\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# подставить нужный путь к папке без закрывающего слэша\n",
    "folder_path = 'LS_Py_Tasks/recursion'\n",
    "\n",
    "if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "    if not os.listdir(folder_path):\n",
    "        print('Directory is empty')\n",
    "    else:    \n",
    "        files = glob.glob(folder_path + '/**/*.txt', recursive = True)\n",
    "else:\n",
    "    print(\"Given directory doesn't exist\")\n",
    "    \n",
    "frequency_dict = {}\n",
    "print('List of .txt files in folder ' + folder_path + ' : \\n')\n",
    "for file in files:\n",
    "    is_binary = is_file_binary(file)\n",
    "    if(is_binary):\n",
    "        print('Type : binary ', file)\n",
    "    else:\n",
    "        print('Type : text   ', file)\n",
    "    if(not is_binary):\n",
    "        freq_dict = find_most_common_words(read_file(file), frequency_dict)\n",
    "\n",
    "\n",
    "print('\\nCommon words in folder ' + folder_path + ' : \\n')\n",
    "for item in freq_dict.keys():\n",
    "    print(item + ': ' + str(freq_dict[item]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
